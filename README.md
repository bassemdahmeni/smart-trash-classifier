ğŸ—‘ï¸ Smart Waste Classification System
An end-to-end deep learning application that classifies waste materials into different categories to facilitate proper recycling and disposal.
Built with PyTorch, Flask, and modern MLOps practices.

ğŸš€ Features
Multi-class Waste Classification â€” Classifies images into 6 categories: cardboard, glass, metal, paper, plastic, and trash

End-to-End Pipeline â€” Complete ML workflow from data ingestion to deployment

Modern Architecture â€” Uses EfficientNet with fine-tuning for optimal performance

REST API â€” Flask-based web interface for easy integration

MLOps Ready â€” DVC for data versioning, GitHub Actions for CI/CD, Docker for containerization

ğŸ—ï¸ System Architecture
ğŸ”¹ Pipeline Stages
Data Ingestion â€” Downloads and organizes the waste dataset

Base Model Preparation â€” Loads and configures EfficientNet backbone

Data Preprocessing â€” Applies transformations and creates data loaders

Model Training â€” Fine-tunes the model with early stopping and callbacks

Model Evaluation â€” Validates performance on the test set

Prediction API â€” Real-time classification via REST endpoints

ğŸ”¹ Model Details
Backbone: EfficientNet-B0/B1 (pretrained weights)

Classifier Head: Custom dense layers with dropout for regularization

Fine-Tuning: Progressive unfreezing of backbone layers

Optimization: Adam optimizer with StepLR scheduler

Loss Function: Cross-Entropy with early stopping

ğŸ› ï¸ Installation & Setup
ğŸ”§ Prerequisites
Python 3.10

Conda / Miniconda

Git

DVC (for data versioning)

âš™ï¸ Local Development
# Clone the repository
git clone <your-repo-url>
cd trash-classification-app

# Create and activate conda environment
conda create -n trash-classification python=3.10
conda activate trash-classification

# Install dependencies
pip install -r requirements.txt

# Setup DVC (if using remote storage)
dvc pull

ğŸ³ Using Docker
# Build the image
docker build -t trash-classification-app .

# Run the container
docker run -p 8080:8080 trash-classification-app

ğŸ“– Usage
ğŸ§  Training the Model
# Run the complete training pipeline
python main.py

# Or via API:
curl -X POST http://localhost:8080/train

train
ğŸ§© Making Predictions
Via API:
curl -X POST http://localhost:8080/predict \
  -H "Content-Type: application/json" \
  -d '{"image": "<base64_encoded_image>"}'

from cnnClassifier.pipeline.predict import PredictionPipeline

predictor = PredictionPipeline()
result = predictor.predict("path/to/your/image.jpg")
print(result)

ğŸŒ API Endpoints
Method	Endpoint	Description
GET	/	Home page with web interface
POST	/train	Trigger model training pipeline
POST	/predict	Classify waste image (expects base64)
ğŸ­ MLOps Infrastructure
ğŸ“¦ Data Version Control (DVC)
Tracks datasets and model artifacts

Ensures reproducible pipelines

Supports remote storage integration

âš™ï¸ CI/CD with GitHub Actions
Automated testing on push/pull requests

Docker image building and publishing

Deployment automation

ğŸ³ Containerization
Fully Dockerized for consistent environments

Conda environment management

Easily deployable to cloud platforms

ğŸŒ Deployment
ğŸ’» Local Deployment
python app.py
# Access at http://localhost:8080

â˜ï¸ Cloud Deployment
AWS: Use port 8080

Azure: Use port 80

Other: Adjust ports in app.py as needed

ğŸ”§ Configuration
Key configuration parameters are defined in config_entity.py:

Model architecture (EfficientNet B0/B1)

Learning rate & optimizer settings

Data augmentation parameters

Training hyperparameters

Path configurations

ğŸ¤ Contributing
Fork the repository

Create a new feature branch

Commit your changes

Push to your branch

Create a Pull Request ğŸš€