{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e516b937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bc2b0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f9fe3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataPreprocessingConfig:\n",
    "    data_dir: Path\n",
    "    batch_size: int\n",
    "    image_size: list\n",
    "    val_split: float\n",
    "    test_split: float\n",
    "    shuffle: bool\n",
    "    random_seed: int\n",
    "    augmentation: bool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d356e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnnClassifier.constants import *\n",
    "from cnnClassifier.utils.common import read_yaml, create_directories\n",
    "# from cnnClassifier.entity import DataPreprocessingConfig\n",
    "from pathlib import Path\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_preprocessing_config(self) -> DataPreprocessingConfig:\n",
    "        config_root_data = self.config.data_ingestion\n",
    "        config = DataPreprocessingConfig(\n",
    "            data_dir=Path(config_root_data.unzip_dir,\"dataset-resized\"),\n",
    "            batch_size=self.params.BATCH_SIZE,\n",
    "            image_size=self.params.IMAGE_SIZE,\n",
    "            val_split=self.params.VAL_SPLIT,\n",
    "            test_split=self.params.TEST_SPLIT,\n",
    "            shuffle=self.params.SHUFFLE_DATASET,\n",
    "            random_seed=self.params.RANDOM_SEED,\n",
    "            augmentation=self.params.AUGMENTATION\n",
    "        )\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d1e3e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "class TrashNetDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.classes = ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "        \n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for class_name in self.classes:\n",
    "            class_dir = os.path.join(data_dir, class_name)\n",
    "            if os.path.exists(class_dir):\n",
    "                for img_file in os.listdir(class_dir):\n",
    "                    if img_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                        self.image_paths.append(os.path.join(class_dir, img_file))\n",
    "                        self.labels.append(self.class_to_idx[class_name])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label\n",
    "\n",
    "\n",
    "class DataPreprocessing:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "\n",
    "    def _get_transforms(self, train=True):\n",
    "        if train and self.config.augmentation:\n",
    "            return transforms.Compose([\n",
    "                transforms.Resize((self.config.image_size[0], self.config.image_size[1])),\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                transforms.RandomRotation(degrees=15),\n",
    "                transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "                transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "        else:\n",
    "            return transforms.Compose([\n",
    "                transforms.Resize((self.config.image_size[0], self.config.image_size[1])),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "\n",
    "    def get_dataloaders(self):\n",
    "        dataset = TrashNetDataset(\n",
    "            data_dir=self.config.data_dir,\n",
    "            transform=None\n",
    "        )\n",
    "        \n",
    "        dataset_size = len(dataset)\n",
    "        test_size = int(self.config.test_split * dataset_size)\n",
    "        val_size = int(self.config.val_split * dataset_size)\n",
    "        train_size = dataset_size - val_size - test_size\n",
    "\n",
    "        if self.config.shuffle:\n",
    "            torch.manual_seed(self.config.random_seed)\n",
    "\n",
    "        train_dataset, val_dataset, test_dataset = random_split(\n",
    "            dataset, [train_size, val_size, test_size]\n",
    "        )\n",
    "\n",
    "        # Apply transforms\n",
    "        train_dataset.dataset.transform = self._get_transforms(train=True)\n",
    "        val_dataset.dataset.transform = self._get_transforms(train=False)\n",
    "        test_dataset.dataset.transform = self._get_transforms(train=False)\n",
    "\n",
    "        # DataLoaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size, shuffle=False)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size, shuffle=False)\n",
    "\n",
    "        return train_loader, val_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b457174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-28 01:07:30,323: INFO: 2741232552: >>>>> Data Preprocessing stage started <<<<<]\n",
      "[2025-09-28 01:07:30,326: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-09-28 01:07:30,328: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-09-28 01:07:30,329: INFO: common: created directory at: artifacts]\n",
      "Train loader batches: 56\n",
      "Validation loader batches: 16\n",
      "Test loader batches: 8\n",
      "Sample batch - images shape: torch.Size([32, 3, 224, 224]), labels shape: torch.Size([32])\n",
      "[2025-09-28 01:07:30,566: INFO: 2741232552: >>>>> Data Preprocessing stage completed <<<<<]\n"
     ]
    }
   ],
   "source": [
    "from cnnClassifier import logger\n",
    "try:\n",
    "    logger.info(\">>>>> Data Preprocessing stage started <<<<<\")\n",
    "    \n",
    "    # Load configuration\n",
    "    config = ConfigurationManager()\n",
    "    data_preprocessing_config = config.get_data_preprocessing_config()\n",
    "    \n",
    "    # Create preprocessing component\n",
    "    preprocessing = DataPreprocessing(config=data_preprocessing_config)\n",
    "    \n",
    "    # Get dataloaders\n",
    "    train_loader, val_loader, test_loader = preprocessing.get_dataloaders()\n",
    "    \n",
    "    # Print some info\n",
    "    print(f\"Train loader batches: {len(train_loader)}\")\n",
    "    print(f\"Validation loader batches: {len(val_loader)}\")\n",
    "    print(f\"Test loader batches: {len(test_loader)}\")\n",
    "    \n",
    "    # Optional sanity check: inspect one batch\n",
    "    images, labels = next(iter(train_loader))\n",
    "    print(f\"Sample batch - images shape: {images.shape}, labels shape: {labels.shape}\")\n",
    "    \n",
    "    logger.info(\">>>>> Data Preprocessing stage completed <<<<<\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.exception(e)\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
